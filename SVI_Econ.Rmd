---
title: "Svi_econ"
author: "pauline"
date: "2023-11-29"
output: html_document
---

```{r Load the data file, echo=T, results='hide'}
SVI_Data <- read.csv("SVI_2020_US.csv")
head(SVI_Data)

econ <- read.csv("ACSDT5Y2020.B19013-Data.csv")
head(econ)

```

#subset to CA tracts

```{r CA tracts, echo=T, results='hide'}
Clean_data <- subset(SVI_Data, select = c(ST,STATE,ST_ABBR,STCNTY,COUNTY,FIPS,LOCATION,AREA_SQMI,EPL_POV150,	EPL_UNEMP,	EPL_HBURD,	EPL_NOHSDP,	EPL_UNINSUR,	SPL_THEME1,	RPL_THEME1,	EPL_AGE65,	EPL_AGE17,	EPL_DISABL,	EPL_SNGPNT,	EPL_LIMENG,	SPL_THEME2,	RPL_THEME2,	EPL_MINRTY,	SPL_THEME3,	RPL_THEME3, E_MINRTY, EP_HISP, EP_ASIAN, EP_AIAN, EPL_MUNIT,	EPL_MOBILE,	EPL_CROWD,	EPL_NOVEH,	EPL_GROUPQ,	SPL_THEME4,	RPL_THEME4,	SPL_THEMES,	RPL_THEMES, E_AGE65, EP_POV150, EP_AGE65, EP_NOHSDP
) )

CA_SVI <- subset(Clean_data, ST_ABBR == "CA")

CA_SVI <- subset(CA_SVI,  RPL_THEMES!= -999 )
CA_SVI <- subset(CA_SVI,  RPL_THEME1!= -999 )
CA_SVI <- subset(CA_SVI,  RPL_THEME2!= -999 )
CA_SVI <- subset(CA_SVI,  RPL_THEME3!= -999 )
CA_SVI <- subset(CA_SVI,  RPL_THEME4!= -999 )
```



#remove first row of headers 

```{r}
#clean data for economic
econ <- subset(econ, select = c(GEO_ID, NAME,B19013_001E))
econ <- econ[-c(1, 2), ] 
head(econ)
```

#rename columns

```{r}
names_to_change <- c("GEO_ID", "NAME", "B19013_001E")
new_names <- c("GEO_ID", "tract", "income")

econ <- setNames(econ, new_names)
```

# edit GEO_ID to isolate just the number after 1400000US06001400100

```{r}
# Assuming 'econ' is your data frame
econ$GEO_ID <- sub(".*US0*(\\d+)", "\\1", econ$GEO_ID)

```

#now join the datasets based on GEO_ID
```{r}
# Assuming 'econ' and 'CA_SVI' are your data frames
svi_econ <- merge(econ, CA_SVI, by.x = "GEO_ID", by.y = "FIPS", all.x = TRUE, all.y = TRUE)

```

#count how many NA 
```{r}
total_na_count <- sum(is.na(svi_econ))
print(total_na_count)
#remove NA

svi_econ <- na.omit(svi_econ)
svi_econ <- svi_econ[svi_econ$income != "-", , drop = FALSE]


#leaves us with 9001 rows 
str(svi_econ$income)
svi_econ$income <- as.numeric(as.character(svi_econ$income))
total_na_count <- sum(is.na(svi_econ))
print(total_na_count)
svi_econ <- na.omit(svi_econ)
#8956

```

#plot histogram of income variable 
```{r}
# Assuming 'merged_data' is your data frame and 'B19013_001E' is the income variable
library(ggplot2)

ggplot(svi_econ, aes(x = income)) +
  geom_histogram(binwidth = 1000, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Income Histogram", x = "Income", y = "Frequency")

#data is skewed right 
```

```{r}
# Assuming 'merged_data' is your data frame and 'B19013_001E' is the income variable
library(ggplot2)

ggplot(svi_econ, aes(x = RPL_THEMES)) +
  geom_histogram(binwidth = 0.01, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Income Histogram", x = "Income", y = "Frequency")

#data is skewed left  


```
```{r}
library(ggplot2)

ggplot(svi_econ, aes(x = "", y = RPL_THEMES)) +
  geom_boxplot(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Boxplot of SVI Score", x = "", y = "Overall SVI")

```
In the CDC/ATSDR SVI Interactive Map, we classify data using quartiles (0 to .2500, .2501 to .5000, .5001 to .7500, .7501 to 1.0) and indicate that the classification goes from least vulnerable to most vulnerable. While we do not have required cutoffs for working with CDC/ATSDR SVI data, categorizing CDC/ATSDR SVI values using a quantile classification (i.e., tertiles, quartiles, quintiles, etc.) is a common approach. If you choose to categorize CDC/ATSDR SVI values, we recommend you do so appropriately based on your question of interest.

```{r}
#The interactive map uses these values:
# Assuming svi_econ is your data frame

# Create quartiles and labels
svi_econ$risk <- cut(svi_econ$RPL_THEMES, breaks = c(0, 0.25, 0.5, 0.75, 1.0), labels = c("low", "lowmed", "medhigh", "high"))

# Plot the data with quartile labels
library(ggplot2)

ggplot(svi_econ, aes(x = risk, fill = risk)) +
  geom_bar() +
  labs(title = "Bar Plot of RPL_THEMES with Quartiles", x = "Quartiles", y = "Count") +
  scale_fill_manual(values = c("low" = "lightblue", "lowmed" = "blue", "medhigh" = "darkblue", "high" = "purple"))

```

Now lets do a ligstic regression on income and svi 
```{r}
# Assuming svi_econ is your data frame


# Split the data into training and testing sets
set.seed(123)  # for reproducibility
train_indices <- sample(seq_len(nrow(svi_econ)), 0.8 * nrow(svi_econ))
train_data <- svi_econ[train_indices, ]
test_data <- svi_econ[-train_indices, ]

# Build logistic regression model
logit_model <- glm(risk ~ income, data = train_data, family = "binomial")

# Summary of the model
summary(logit_model)

# Predict on the test set
logit_predictions <- predict(logit_model, test_data, type = "response")

# Convert logistic regression probabilities to predicted classes
logit_predictions_class <- cut(logit_predictions, breaks = c(0, 0.25, 0.5, 0.75, 1.0), labels = c("low", "lowmed", "medhigh", "high"))

# Evaluate the model (e.g., confusion matrix, accuracy, etc.)
conf_matrix <- table(logit_predictions_class, test_data$risk)
print(conf_matrix)

```

ok but now lets also see what other features are relevant to us in this dataset in predicting svi 

first lets select the variables we should look at/consider 

```{r}
# Assuming svi_econ is your data frame

# Specify the features you want to evaluate
features_to_evaluate <- c("income", "COUNTY", "LOCATION", "EPL_POV150", "EPL_POV150", "EPL_UNEMP", "EPL_HBURD", "EPL_NOHSDP", "EPL_UNINSUR", "EPL_AGE65", "EPL_AGE17", "EPL_DISABL", "EPL_SNGPNT", "EPL_LIMENG", "EPL_MINRTY", "E_MINRTY", "EP_HISP", "EP_ASIAN", "EP_AIAN", "EPL_MUNIT", "EPL_MOBILE", "EPL_CROWD", "EPL_NOVEH", "EPL_GROUPQ", "E_AGE65", "EP_POV150", "EP_AGE65", "EP_NOHSDP", "risk")

# Create a subset of the data with only the specified features
svi_predict <- svi_econ[, features_to_evaluate]


```






















#### dont run 

```{r}
# Install and load necessary packages
install.packages("rpart")
library(rpart)


# Split the data into training and testing sets
set.seed(123)  # for reproducibility
train_indices <- sample(seq_len(nrow(svi_econ)), 0.8 * nrow(svi_econ))
train_data <- svi_econ[train_indices, ]
test_data <- svi_econ[-train_indices, ]

# Classification Tree Model
tree_model <- rpart(risk ~ income, data = train_data, method = "class")

# Plot the tree
plot(tree_model)
text(tree_model)

# Predict on the test set
tree_predictions <- predict(tree_model, test_data, type = "class")


```
```{r}

# Logistic Regression Model
logit_model <- glm(risk ~ income, data = train_data, family = "binomial")

# Predict on the test set
logit_predictions <- predict(logit_model, test_data, type = "response")

# Convert logistic regression probabilities to predicted classes
logit_predictions_class <- ifelse(logit_predictions > 0.5, "high", "low")

# Evaluate the models (e.g., confusion matrix, accuracy, etc.)
```

