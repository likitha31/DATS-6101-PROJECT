






```{r, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
library(ezids)
library(ggplot2)
#install.packages("tigris")
library(tigris)
#install.packages("sf")
library(sf)
#install.packages("here")
library(here)
#install.packages("dplyr")
library(dplyr)
#install.packages("leaflet")
library(leaflet)
#install.packages("reshape2")
library(reshape2)
#install.packages("tmap")
library(tmap)
#install.packages("viridis")
library(viridis)
#install.packages("stargazer")
library(stargazer)


```




```{r}

SVI_Data <- read.csv("SVI_2020_US.csv")
us_cases <- read.csv('USAFacts/confirmed-covid-19-cases-in-us-by-state-and-county.csv')
us_deaths <- read.csv('USAFacts/confirmed-covid-19-deaths-in-us-by-state-and-county.csv')

head(SVI_Data)
head(us_cases)
head(us_deaths)

```


```{r}
library(dplyr)
Clean_data <- subset(SVI_Data, ST_ABBR == "CA")
CA_SVI <- subset(Clean_data, select = c(STATE,STCNTY,COUNTY,FIPS,EP_POV150,EP_LIMENG,EP_AGE65, EP_MINRTY,	EP_UNEMP,	EP_NOHSDP,EP_AGE17,EP_DISABL,EP_SNGPNT,EP_MUNIT,EP_MOBILE,EP_CROWD,EP_NOVEH,EP_GROUPQ,RPL_THEMES) )

# Renaming columns
colnames(CA_SVI)[colnames(CA_SVI) == 'STCNTY'] <- 'county_fips'
us_cases <- rename(us_cases, confirmed_cases = confirmed)


# Filter out rows with any value equal to -999
CA_SVI <- CA_SVI[rowSums(CA_SVI == -999, na.rm = TRUE) == 0, ]

# Drop rows with missing values
CA_SVI <- na.omit(CA_SVI)




```




```{r}
# Filter out rows with any value equal to -999
CA_SVI <- CA_SVI[rowSums(CA_SVI == -999, na.rm = TRUE) == 0, ]

# Drop rows with missing values
CA_SVI <- na.omit(CA_SVI)

head(CA_SVI)
head(CA_SVI)
svidata<-CA_SVI





```

```{r}
covid19_cases<-us_cases
covid19_deaths<-us_deaths

covid19_cases<-subset(covid19_cases, state_name=='CA')
covid19_deaths<-subset(covid19_deaths, state_name=='CA')



```



```{r}

# Load the dplyr package
library(dplyr)

# Calculate total cases and deaths for each county
covid19 <- covid19 %>%
  group_by(county_fips) %>%
  mutate(total_cases = sum(confirmed_cases),
         total_deaths = sum(deaths)) %>%
  ungroup()


```


```{r}

tail(covid19)

```

```{r}


# Create a new dataframe with total cases and deaths for each county
summary_data <- covid19 %>%
  group_by(county_fips) %>%
  summarize(total_cases = sum(confirmed_cases),
            total_deaths = sum(deaths))

# Display the new dataframe
print(summary_data)


```

```{r}
#merging svi and summary_data
svi_covid <- merge(svidata, summary_data, by = "county_fips", all.x = TRUE)


```



```{r}
# Load required libraries

library(rpart)
library(caret)

# Assuming your dataset is named 'svi_covid'
# Replace 'your_data.csv' with the actual file name or provide the data directly if it's in a different format

# Example if the data is in a CSV file
# your_data <- read.csv("your_data.csv")

# Example if the data is already loaded
your_data <- svi_covid

# Assuming you want to predict 'total_cases' based on other variables
formula <- total_cases ~ EP_POV150 + EP_LIMENG + EP_AGE65 + EP_MINRTY + EP_UNEMP + EP_NOHSDP 


# Convert categorical variables to factors with consistent levels
your_data$STATE <- as.factor(your_data$STATE)
your_data$COUNTY <- as.factor(your_data$COUNTY)

# Split the data into training and testing sets
set.seed(123)
train_indices <- createDataPartition(your_data$total_cases, p = 0.7, list = FALSE)
train_data <- your_data[train_indices, ]
test_data <- your_data[-train_indices, ]

# Build the decision tree model
tree_model <- rpart(formula, data = train_data, method = "anova")

# Make predictions on the test set
predictions <- predict(tree_model, newdata = test_data)


confusionMatrix(predictions, test_data$total_cases)




```



```{r}




head(svi_covid)




```






```{r}
library(rpart)
library(caret)





formula <- RPL_THEMES ~ total_cases + total_deaths+ EP_POV150 + EP_AGE65 

# Convert categorical variables to factors with consistent levels
svi_covid$STATE <- as.factor(svi_covid$STATE)
svi_covid$COUNTY <- as.factor(svi_covid$COUNTY)

# Ensure 'RPL_THEMES' is a numeric variable
svi_covid$RPL_THEMES <- as.numeric(svi_covid$RPL_THEMES)

# Split the data into training and testing sets
set.seed(123)
train_indices <- createDataPartition(svi_covid$RPL_THEMES, p = 0.7, list = FALSE)
train_data <- svi_covid[train_indices, ]
test_data <- svi_covid[-train_indices, ]

# Build the decision tree regression model
tree_model <- rpart(formula, data = train_data, method = "anova")

# Make predictions on the test set
predictions <- predict(tree_model, newdata = test_data)

# Evaluate the model's performance (you might want to use regression metrics)
cor(predictions, test_data$RPL_THEMES)  # Correlation as an example

# Visualize the decision tree (optional)
plot(tree_model)
text(tree_model)


png("C:/Users/lucky/OneDrive/Documents/Zoom/decision_tree.png", width = 800, height = 600)
plot(tree_model)
text(tree_model)
dev.off()


```



